{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f344bd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing embeddings...\n",
      "Epoch0: 1009/3000(33.63%)\n",
      "Epoch1: 1496/3000(49.87%)\n",
      "Epoch2: 1885/3000(62.83%)\n",
      "Epoch3: 2064/3000(68.80%)\n",
      "Epoch4: 2156/3000(71.87%)\n",
      "Epoch5: 2226/3000(74.20%)\n",
      "Epoch6: 2261/3000(75.37%)\n",
      "Epoch7: 2301/3000(76.70%)\n",
      "Epoch8: 2340/3000(78.00%)\n",
      "Epoch9: 2358/3000(78.60%)\n",
      "Epoch10: 2375/3000(79.17%)\n",
      "Epoch11: 2395/3000(79.83%)\n",
      "Epoch12: 2402/3000(80.07%)\n",
      "Epoch13: 2421/3000(80.70%)\n",
      "Epoch14: 2426/3000(80.87%)\n",
      "Epoch15: 2433/3000(81.10%)\n",
      "Epoch16: 2432/3000(81.07%)\n",
      "Epoch17: 2441/3000(81.37%)\n",
      "Epoch18: 2442/3000(81.40%)\n",
      "Epoch19: 2452/3000(81.73%)\n",
      "Epoch20: 2460/3000(82.00%)\n",
      "Epoch21: 2461/3000(82.03%)\n",
      "Epoch22: 2459/3000(81.97%)\n",
      "Epoch23: 2467/3000(82.23%)\n",
      "Epoch24: 2476/3000(82.53%)\n",
      "Epoch25: 2477/3000(82.57%)\n",
      "Epoch26: 2477/3000(82.57%)\n",
      "Epoch27: 2475/3000(82.50%)\n",
      "Epoch28: 2482/3000(82.73%)\n",
      "Epoch29: 2486/3000(82.87%)\n",
      "Epoch30: 2485/3000(82.83%)\n",
      "Epoch31: 2490/3000(83.00%)\n",
      "Epoch32: 2487/3000(82.90%)\n",
      "Epoch33: 2498/3000(83.27%)\n",
      "Epoch34: 2494/3000(83.13%)\n",
      "Epoch35: 2506/3000(83.53%)\n",
      "Epoch36: 2502/3000(83.40%)\n",
      "Epoch37: 2502/3000(83.40%)\n",
      "Epoch38: 2509/3000(83.63%)\n",
      "Epoch39: 2505/3000(83.50%)\n",
      "Epoch40: 2510/3000(83.67%)\n",
      "Epoch41: 2513/3000(83.77%)\n",
      "Epoch42: 2511/3000(83.70%)\n",
      "Epoch43: 2519/3000(83.97%)\n",
      "Epoch44: 2516/3000(83.87%)\n",
      "Epoch45: 2521/3000(84.03%)\n",
      "Epoch46: 2519/3000(83.97%)\n",
      "Epoch47: 2530/3000(84.33%)\n",
      "Epoch48: 2530/3000(84.33%)\n",
      "Epoch49: 2524/3000(84.13%)\n",
      "Epoch50: 2526/3000(84.20%)\n",
      "Epoch51: 2528/3000(84.27%)\n",
      "Epoch52: 2532/3000(84.40%)\n",
      "Epoch53: 2532/3000(84.40%)\n",
      "Epoch54: 2534/3000(84.47%)\n",
      "Epoch55: 2540/3000(84.67%)\n",
      "Epoch56: 2537/3000(84.57%)\n",
      "Epoch57: 2545/3000(84.83%)\n",
      "Epoch58: 2541/3000(84.70%)\n",
      "Epoch59: 2545/3000(84.83%)\n",
      "Epoch60: 2545/3000(84.83%)\n",
      "Epoch61: 2544/3000(84.80%)\n",
      "Epoch62: 2549/3000(84.97%)\n",
      "Epoch63: 2550/3000(85.00%)\n",
      "Epoch64: 2549/3000(84.97%)\n",
      "Epoch65: 2549/3000(84.97%)\n",
      "Epoch66: 2556/3000(85.20%)\n",
      "Epoch67: 2552/3000(85.07%)\n",
      "Epoch68: 2555/3000(85.17%)\n",
      "Epoch69: 2544/3000(84.80%)\n",
      "Epoch70: 2559/3000(85.30%)\n",
      "Epoch71: 2561/3000(85.37%)\n",
      "Epoch72: 2561/3000(85.37%)\n",
      "Epoch73: 2554/3000(85.13%)\n",
      "Epoch74: 2557/3000(85.23%)\n",
      "Epoch75: 2556/3000(85.20%)\n",
      "Epoch76: 2563/3000(85.43%)\n",
      "Epoch77: 2563/3000(85.43%)\n",
      "Epoch78: 2565/3000(85.50%)\n",
      "Epoch79: 2560/3000(85.33%)\n",
      "Epoch80: 2561/3000(85.37%)\n",
      "Epoch81: 2558/3000(85.27%)\n",
      "Epoch82: 2558/3000(85.27%)\n",
      "Epoch83: 2555/3000(85.17%)\n",
      "Epoch84: 2559/3000(85.30%)\n",
      "Epoch85: 2557/3000(85.23%)\n",
      "Epoch86: 2559/3000(85.30%)\n",
      "Epoch87: 2567/3000(85.57%)\n",
      "Epoch88: 2562/3000(85.40%)\n",
      "Epoch89: 2562/3000(85.40%)\n",
      "Epoch90: 2562/3000(85.40%)\n",
      "Epoch91: 2564/3000(85.47%)\n",
      "Epoch92: 2559/3000(85.30%)\n",
      "Epoch93: 2565/3000(85.50%)\n",
      "Epoch94: 2570/3000(85.67%)\n",
      "Epoch95: 2570/3000(85.67%)\n",
      "Epoch96: 2564/3000(85.47%)\n",
      "Epoch97: 2566/3000(85.53%)\n",
      "Epoch98: 2561/3000(85.37%)\n",
      "Epoch99: 2564/3000(85.47%)\n",
      "Epoch100: 2561/3000(85.37%)\n",
      "Epoch101: 2566/3000(85.53%)\n",
      "Epoch102: 2572/3000(85.73%)\n",
      "Epoch103: 2566/3000(85.53%)\n",
      "Epoch104: 2571/3000(85.70%)\n",
      "Epoch105: 2566/3000(85.53%)\n",
      "Epoch106: 2568/3000(85.60%)\n",
      "Epoch107: 2566/3000(85.53%)\n",
      "Epoch108: 2569/3000(85.63%)\n",
      "Epoch109: 2565/3000(85.50%)\n",
      "Epoch110: 2568/3000(85.60%)\n",
      "Epoch111: 2572/3000(85.73%)\n",
      "Early stopping due to no improvement in validation accuracy for 10 epochs\n",
      "Training complete\n",
      "Iteration 1, loss = 0.54310146\n",
      "Iteration 2, loss = 0.36076883\n",
      "Iteration 3, loss = 0.32778264\n",
      "Iteration 4, loss = 0.29362445\n",
      "Iteration 5, loss = 0.26601724\n",
      "Iteration 6, loss = 0.23777523\n",
      "Iteration 7, loss = 0.21510687\n",
      "Iteration 8, loss = 0.18845410\n",
      "Iteration 9, loss = 0.17716101\n",
      "Iteration 10, loss = 0.17168323\n",
      "Iteration 11, loss = 0.13137400\n",
      "Iteration 12, loss = 0.12888064\n",
      "Iteration 13, loss = 0.11056142\n",
      "Iteration 14, loss = 0.09690344\n",
      "Iteration 15, loss = 0.10946325\n",
      "Iteration 16, loss = 0.10001117\n",
      "Iteration 17, loss = 0.10155243\n",
      "Iteration 18, loss = 0.07752109\n",
      "Iteration 19, loss = 0.08776271\n",
      "Iteration 20, loss = 0.06145672\n",
      "Iteration 21, loss = 0.06566150\n",
      "Iteration 22, loss = 0.05121727\n",
      "Iteration 23, loss = 0.04986975\n",
      "Iteration 24, loss = 0.05412688\n",
      "Iteration 25, loss = 0.05887691\n",
      "Iteration 26, loss = 0.03494769\n",
      "Iteration 27, loss = 0.04915218\n",
      "Iteration 28, loss = 0.06851974\n",
      "Iteration 29, loss = 0.05339519\n",
      "Iteration 30, loss = 0.04764726\n",
      "Iteration 31, loss = 0.04218707\n",
      "Iteration 32, loss = 0.05429336\n",
      "Iteration 33, loss = 0.04646837\n",
      "Iteration 34, loss = 0.05534004\n",
      "Iteration 35, loss = 0.05251212\n",
      "Iteration 36, loss = 0.04677457\n",
      "Iteration 37, loss = 0.03172422\n",
      "Iteration 38, loss = 0.03371892\n",
      "Iteration 39, loss = 0.03602156\n",
      "Iteration 40, loss = 0.03469653\n",
      "Iteration 41, loss = 0.05639189\n",
      "Iteration 42, loss = 0.05117917\n",
      "Iteration 43, loss = 0.04019230\n",
      "Iteration 44, loss = 0.04908872\n",
      "Iteration 45, loss = 0.03134139\n",
      "Iteration 46, loss = 0.03886497\n",
      "Iteration 47, loss = 0.04371958\n",
      "Iteration 48, loss = 0.03852270\n",
      "Iteration 49, loss = 0.02874906\n",
      "Iteration 50, loss = 0.02569663\n",
      "Iteration 51, loss = 0.01409666\n",
      "Iteration 52, loss = 0.02845415\n",
      "Iteration 53, loss = 0.05926352\n",
      "Iteration 54, loss = 0.02831176\n",
      "Iteration 55, loss = 0.04442854\n",
      "Iteration 56, loss = 0.04583427\n",
      "Iteration 57, loss = 0.03113508\n",
      "Iteration 58, loss = 0.02961389\n",
      "Iteration 59, loss = 0.02174230\n",
      "Iteration 60, loss = 0.02786023\n",
      "Iteration 61, loss = 0.06082847\n",
      "Iteration 62, loss = 0.04375404\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "baseline Accuracy: 0.864\n",
      "Test Accuracy: 0.8586666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier as sklearn_mlp\n",
    "from custom_mlp import mlpClassifier as mlp\n",
    "from demo import runner\n",
    "CONFIGS = {\n",
    "    \"data_path\": \"../project_data/t4sa_data.csv\",\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "runner(CONFIGS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
